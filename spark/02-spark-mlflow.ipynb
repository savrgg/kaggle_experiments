{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/Users/salvadorgarcia/Repos/kaggle_experiments/spark/mlflow.yaml/.trash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m     spark\u001b[39m.\u001b[39mstop()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     main()\n",
      "\u001b[1;32m/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m data \u001b[39m=\u001b[39m [(\u001b[39m1.0\u001b[39m, Vectors\u001b[39m.\u001b[39mdense(\u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         (\u001b[39m2.0\u001b[39m, Vectors\u001b[39m.\u001b[39mdense(\u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         (\u001b[39m3.0\u001b[39m, Vectors\u001b[39m.\u001b[39mdense(\u001b[39m0.3\u001b[39m, \u001b[39m0.4\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m         (\u001b[39m49.0\u001b[39m, Vectors\u001b[39m.\u001b[39mdense(\u001b[39m4.9\u001b[39m, \u001b[39m5.0\u001b[39m)),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m         (\u001b[39m50.0\u001b[39m, Vectors\u001b[39m.\u001b[39mdense(\u001b[39m5.0\u001b[39m, \u001b[39m5.1\u001b[39m))]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m \u001b[39m# Train the Linear Regression model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m lr_model, test_data, spark \u001b[39m=\u001b[39m train_linear_regression_model(data, train_fraction\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m# Score the model on the test data\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m predictions \u001b[39m=\u001b[39m score_linear_regression_model(lr_model, test_data, spark)\n",
      "\u001b[1;32m/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m mlflow\u001b[39m.\u001b[39mset_tracking_uri(\u001b[39m\"\u001b[39m\u001b[39mfile://\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(mlflow_config_file))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Create an MLflow run\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39;49mstart_run():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m\"\u001b[39m\u001b[39mtrain_fraction\u001b[39m\u001b[39m\"\u001b[39m, train_fraction)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/salvadorgarcia/Repos/kaggle_experiments/spark/02-spark-mlflow.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# Create a DataFrame with the correct data type\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/fluent.py:293\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_active_run_stack) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m nested:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         (\n\u001b[1;32m    288\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mRun with UUID \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is already active. To start a new run, first end the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m         )\u001b[39m.\u001b[39mformat(_active_run_stack[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id)\n\u001b[1;32m    292\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m client \u001b[39m=\u001b[39m MlflowClient()\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m run_id:\n\u001b[1;32m    295\u001b[0m     existing_run_id \u001b[39m=\u001b[39m run_id\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/client.py:81\u001b[0m, in \u001b[0;36mMlflowClient.__init__\u001b[0;34m(self, tracking_uri, registry_uri)\u001b[0m\n\u001b[1;32m     79\u001b[0m final_tracking_uri \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39m_resolve_tracking_uri(tracking_uri)\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registry_uri \u001b[39m=\u001b[39m registry_utils\u001b[39m.\u001b[39m_resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tracking_client \u001b[39m=\u001b[39m TrackingServiceClient(final_tracking_uri)\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:51\u001b[0m, in \u001b[0;36mTrackingServiceClient.__init__\u001b[0;34m(self, tracking_uri)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracking_uri \u001b[39m=\u001b[39m tracking_uri\n\u001b[1;32m     47\u001b[0m \u001b[39m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m# self.store  # pylint: disable=pointless-statement\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:55\u001b[0m, in \u001b[0;36mTrackingServiceClient.store\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstore\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 55\u001b[0m     \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39;49m_get_store(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtracking_uri)\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/utils.py:214\u001b[0m, in \u001b[0;36m_get_store\u001b[0;34m(store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_store\u001b[39m(store_uri\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, artifact_uri\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 214\u001b[0m     \u001b[39mreturn\u001b[39;00m _tracking_store_registry\u001b[39m.\u001b[39;49mget_store(store_uri, artifact_uri)\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/registry.py:39\u001b[0m, in \u001b[0;36mTrackingStoreRegistry.get_store\u001b[0;34m(self, store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtracking\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tracking_service\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m     38\u001b[0m resolved_store_uri \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39m_resolve_tracking_uri(store_uri)\n\u001b[0;32m---> 39\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_store_with_resolved_uri(resolved_store_uri, artifact_uri)\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/registry.py:49\u001b[0m, in \u001b[0;36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[0;34m(self, resolved_store_uri, artifact_uri)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mRetrieve the store associated with a resolved (non-None) store URI and an artifact URI.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mCaching is done on resolved URIs because the meaning of an unresolved (None) URI may change\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mdepending on external configuration, such as environment variables\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m builder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_store_builder(resolved_store_uri)\n\u001b[0;32m---> 49\u001b[0m \u001b[39mreturn\u001b[39;00m builder(store_uri\u001b[39m=\u001b[39;49mresolved_store_uri, artifact_uri\u001b[39m=\u001b[39;49martifact_uri)\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/utils.py:129\u001b[0m, in \u001b[0;36m_get_file_store\u001b[0;34m(store_uri, **_)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_file_store\u001b[39m(store_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m FileStore(store_uri, store_uri)\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:176\u001b[0m, in \u001b[0;36mFileStore.__init__\u001b[0;34m(self, root_directory, artifact_root_uri)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m# Create trash folder if needed\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrash_folder):\n\u001b[0;32m--> 176\u001b[0m     mkdir(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrash_folder)\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/utils/file_utils.py:192\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mEEXIST \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(target):\n\u001b[0;32m--> 192\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/Repos/kaggle_experiments/spark/.venv/lib/python3.9/site-packages/mlflow/utils/file_utils.py:189\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    187\u001b[0m target \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, name) \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m root\n\u001b[1;32m    188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(target)\n\u001b[1;32m    190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mEEXIST \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(target):\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.18/Frameworks/Python.framework/Versions/3.9/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/Users/salvadorgarcia/Repos/kaggle_experiments/spark/mlflow.yaml/.trash'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"LinearRegressionExample\").getOrCreate()\n",
    "\n",
    "def train_linear_regression_model(data, train_fraction=0.8):\n",
    "    # Create a Spark session\n",
    "    spark = SparkSession.builder.appName(\"LinearRegressionExample\").getOrCreate()\n",
    "\n",
    "    # Specify the MLflow YAML configuration file\n",
    "    mlflow_config_file = \"/Users/salvadorgarcia/Repos/kaggle_experiments/spark/mlflow.yaml\"\n",
    "\n",
    "    # Load the MLflow configuration from the YAML file\n",
    "    mlflow.set_tracking_uri(\"file://{}\".format(mlflow_config_file))\n",
    "\n",
    "    # Create an MLflow run\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"train_fraction\", train_fraction)\n",
    "        \n",
    "        # Create a DataFrame with the correct data type\n",
    "        df = spark.createDataFrame(data, [\"label\", \"features\"]).withColumn(\"features\", col(\"features\").cast(VectorUDT()))\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        train_data, test_data = df.randomSplit([train_fraction, 1 - train_fraction], seed=123)\n",
    "\n",
    "        # Create a LinearRegression model\n",
    "        lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        lr_model = lr.fit(train_data)\n",
    "\n",
    "        # Log model parameters\n",
    "        mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "\n",
    "        # Log the model itself\n",
    "        mlflow.spark.log_model(lr_model, \"model\")\n",
    "\n",
    "        return lr_model, test_data, spark\n",
    "\n",
    "def score_linear_regression_model(model, test_data,spark):\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.transform(test_data)\n",
    "    return predictions\n",
    "\n",
    "def evaluate_linear_regression_model(predictions):\n",
    "    # Check if there are any predictions\n",
    "    if predictions.count() > 0:\n",
    "        # Evaluate the model\n",
    "        evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        \n",
    "        # Log RMSE as a metric\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "\n",
    "        return rmse\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def main():\n",
    "    # Create a larger synthetic dataset with 50 data points\n",
    "    data = [(1.0, Vectors.dense(0.1, 0.2)),\n",
    "            (2.0, Vectors.dense(0.2, 0.3)),\n",
    "            (3.0, Vectors.dense(0.3, 0.4)),\n",
    "            (4.0, Vectors.dense(0.4, 0.5)),\n",
    "            (5.0, Vectors.dense(0.5, 0.6)),\n",
    "            (6.0, Vectors.dense(0.6, 0.7)),\n",
    "            (7.0, Vectors.dense(0.7, 0.8)),\n",
    "            (8.0, Vectors.dense(0.8, 0.9)),\n",
    "            (9.0, Vectors.dense(0.9, 1.0)),\n",
    "            (10.0, Vectors.dense(1.0, 1.1)),\n",
    "            (11.0, Vectors.dense(1.1, 1.2)),\n",
    "            (12.0, Vectors.dense(1.2, 1.3)),\n",
    "            (13.0, Vectors.dense(1.3, 1.4)),\n",
    "            (14.0, Vectors.dense(1.4, 1.5)),\n",
    "            (15.0, Vectors.dense(1.5, 1.6)),\n",
    "            (16.0, Vectors.dense(1.6, 1.7)),\n",
    "            (17.0, Vectors.dense(1.7, 1.8)),\n",
    "            (18.0, Vectors.dense(1.8, 1.9)),\n",
    "            (19.0, Vectors.dense(1.9, 2.0)),\n",
    "            (20.0, Vectors.dense(2.0, 2.1)),\n",
    "            (21.0, Vectors.dense(2.1, 2.2)),\n",
    "            (22.0, Vectors.dense(2.2, 2.3)),\n",
    "            (23.0, Vectors.dense(2.3, 2.4)),\n",
    "            (24.0, Vectors.dense(2.4, 2.5)),\n",
    "            (25.0, Vectors.dense(2.5, 2.6)),\n",
    "            (26.0, Vectors.dense(2.6, 2.7)),\n",
    "            (27.0, Vectors.dense(2.7, 2.8)),\n",
    "            (28.0, Vectors.dense(2.8, 2.9)),\n",
    "            (29.0, Vectors.dense(2.9, 3.0)),\n",
    "            (30.0, Vectors.dense(3.0, 3.1)),\n",
    "            (31.0, Vectors.dense(3.1, 3.2)),\n",
    "            (32.0, Vectors.dense(3.2, 3.3)),\n",
    "            (33.0, Vectors.dense(3.3, 3.4)),\n",
    "            (34.0, Vectors.dense(3.4, 3.5)),\n",
    "            (35.0, Vectors.dense(3.5, 3.6)),\n",
    "            (36.0, Vectors.dense(3.6, 3.7)),\n",
    "            (37.0, Vectors.dense(3.7, 3.8)),\n",
    "            (38.0, Vectors.dense(3.8, 3.9)),\n",
    "            (39.0, Vectors.dense(3.9, 4.0)),\n",
    "            (40.0, Vectors.dense(4.0, 4.1)),\n",
    "            (41.0, Vectors.dense(4.1, 4.2)),\n",
    "            (42.0, Vectors.dense(4.2, 4.3)),\n",
    "            (43.0, Vectors.dense(4.3, 4.4)),\n",
    "            (44.0, Vectors.dense(4.4, 4.5)),\n",
    "            (45.0, Vectors.dense(4.5, 4.6)),\n",
    "            (46.0, Vectors.dense(4.6, 4.7)),\n",
    "            (47.0, Vectors.dense(4.7, 4.8)),\n",
    "            (48.0, Vectors.dense(4.8, 4.9)),\n",
    "            (49.0, Vectors.dense(4.9, 5.0)),\n",
    "            (50.0, Vectors.dense(5.0, 5.1))]\n",
    "\n",
    "    # Train the Linear Regression model\n",
    "    lr_model, test_data, spark = train_linear_regression_model(data, train_fraction=0.8)\n",
    "\n",
    "    # Score the model on the test data\n",
    "    predictions = score_linear_regression_model(lr_model, test_data, spark)\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse = evaluate_linear_regression_model(predictions)\n",
    "\n",
    "    if rmse is not None:\n",
    "        print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    else:\n",
    "        print(\"No predictions were made. Check your data or model.\")\n",
    "\n",
    "    # Stop the Spark session\n",
    "    spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-26 23:19:35 -0600] [31923] [INFO] Starting gunicorn 21.2.0\n",
      "[2023-10-26 23:19:35 -0600] [31923] [INFO] Listening at: http://127.0.0.1:5000 (31923)\n",
      "[2023-10-26 23:19:35 -0600] [31923] [INFO] Using worker: sync\n",
      "[2023-10-26 23:19:35 -0600] [31924] [INFO] Booting worker with pid: 31924\n",
      "[2023-10-26 23:19:35 -0600] [31925] [INFO] Booting worker with pid: 31925\n",
      "[2023-10-26 23:19:35 -0600] [31926] [INFO] Booting worker with pid: 31926\n",
      "[2023-10-26 23:19:35 -0600] [31927] [INFO] Booting worker with pid: 31927\n",
      "^C\n",
      "[2023-10-26 23:19:44 -0600] [31923] [INFO] Handling signal: int\n",
      "[2023-10-26 23:19:44 -0600] [31925] [INFO] Worker exiting (pid: 31925)\n",
      "[2023-10-26 23:19:44 -0600] [31924] [INFO] Worker exiting (pid: 31924)\n",
      "[2023-10-26 23:19:44 -0600] [31927] [INFO] Worker exiting (pid: 31927)\n",
      "[2023-10-26 23:19:44 -0600] [31926] [INFO] Worker exiting (pid: 31926)\n"
     ]
    }
   ],
   "source": [
    "#!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
